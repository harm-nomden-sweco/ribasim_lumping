{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ribasim_lumping import RibasimLumpingNetwork\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pydantic import BaseModel\n",
    "import xarray as xr\n",
    "import dfm_tools as dfmt\n",
    "import xugrid as xu\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)\n",
    "\n",
    "import networkx as nx\n",
    "import ribasim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base directory and results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"..\\\\..\\\\ribasim_lumping_data\\\\\")\n",
    "results_dir = Path(base_dir, \"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define network name and load areas (discharge units: afwaterende eenheden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"zutphen_tki_netwerk\"\n",
    "\n",
    "areas_file_path = Path(base_dir, \"afw_eenheden\\\\wrij_afwateringseenheden_clip_Zutphen.shp\")\n",
    "areas_gdf = gpd.read_file(areas_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create networkanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RibasimLumpingNetwork(name=network_name, areas_gdf=areas_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select simulation sets and extract all data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add_data_from_simulations_set(\n",
    "    set_name=\"winter\",\n",
    "    simulations_dir=Path(base_dir, \"d-hydro\\\\\"),\n",
    "    simulations_names=[\"tki_zuthpen_berkel_basis.dsproj\"],\n",
    "    simulations_ts=pd.date_range(\"2000-01-02 23:00\", periods=9, freq=\"2D\"),\n",
    ")\n",
    "network.add_data_from_simulations_set(\n",
    "    set_name=\"zomer\",\n",
    "    simulations_dir=Path(base_dir, \"d-hydro\\\\\"),\n",
    "    simulations_names=[\"tki_zuthpen_berkel_basis.dsproj\"],\n",
    "    simulations_ts=pd.date_range(\"2000-01-02 23:00\", periods=9, freq=\"2D\"),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read network data and extract all objects (weirs/pumps/laterals/confluences/bifurcations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.get_network_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define node_ids on which to split the network into Ribasim basins:\n",
    "- define types to include\n",
    "- define additional split nodes by id\n",
    "- define which of the node_ids should be excluded\n",
    "- combine types of split_node_ids\n",
    "- add split_nodes to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add_split_nodes(\n",
    "    weirs=True,\n",
    "    pumps=True,\n",
    "    bifurcations=False,\n",
    "    confluences=False,\n",
    "    split_node_ids_to_include=[1444, 1448, 1377, 2378, 419, 1183],\n",
    "    split_node_ids_to_exclude=[314]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create basins (gdf) based on nodes, edges, split_node_ids and areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.create_basins_based_on_split_nodes();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export it to geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.export_to_geopackage(output_dir=results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a shapefile with point locations as input and get the nearest nodes as split locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_nodes = gpd.read_file(Path(results_dir, network.name, 'ribasim_network.gpkg'), layer='split_nodes')\n",
    "# network.add_split_nodes_based_on_locations(split_nodes=split_nodes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.create_basins_based_on_split_nodes()\n",
    "# network.export_to_geopackage(output_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribasim",
   "language": "python",
   "name": "ribasim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
