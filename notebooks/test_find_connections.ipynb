{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ribasim_lumping import RibasimLumpingNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base_dir, results_dir and network name\n",
    "base_dir = Path(\"..\\\\..\\\\ribasim_lumping_data\\\\\")\n",
    "results_dir = Path(base_dir, \"results\")\n",
    "network_name = \"zutphen_tki_netwerk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load areas (discharge units: afwaterende eenheden)\n",
    "areas_file_path = Path(base_dir, \"afw_eenheden\\\\wrij_afwateringseenheden_selectie_Zutphen.shp\")\n",
    "areas_gdf = gpd.read_file(areas_file_path)\n",
    "areas_gdf = areas_gdf[['GFEIDENT', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networkanalysis\n",
    "network = RibasimLumpingNetwork(\n",
    "    name=network_name, \n",
    "    results_dir=results_dir,\n",
    "    areas_gdf=areas_gdf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select simulation sets and extract all data using xugrid/ugrid\n",
    "network.add_data_from_simulations_set(\n",
    "    set_name=\"winter\",\n",
    "    simulations_dir=Path(base_dir, \"d-hydro\\\\\"),\n",
    "    simulations_names=[\"tki_zuthpen_berkel_basis.dsproj\"],\n",
    "    simulations_ts=pd.date_range(\"2000-01-02 23:00\", periods=9, freq=\"2D\"),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read network data and extract all objects (weirs/pumps/laterals/confluences/bifurcations)\n",
    "network.get_network_data()\n",
    "# Export to geopackage\n",
    "network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define locations where the network should be split into Ribasim basins:\n",
    "\n",
    "network.add_split_nodes(\n",
    "    weirs=True,\n",
    "    pumps=True,\n",
    "    uniweirs=True,\n",
    "    structures_ids_to_include=[\n",
    "        'kdu_DR80760025', # duiker vispassage bovenstrooms\n",
    "        'kst_ST80830001', 'kst_ST80810015', # onderdoorlaten bij verdeelpunt De Berkel (Zutphen)\n",
    "        'kdu_DR84930010', # duiker met terugslagklep Zutphen Noorderhaven (parallel aan gemaal)\n",
    "        'kdu_DR80950033', # duikers voor wijk Leesten\n",
    "        'kdu_DR80940046', 'kdu_DR80950043', 'kdu_DR80950151' # duikers voor wijk Zuidwijken\n",
    "    ], \n",
    "    structures_ids_to_exclude=[\n",
    "        'BCAL_3', 'BCAL_11', # stuwen voor hoogwaterafvoer De Berkel\n",
    "        'BBypass_Besselink_1', 'BBypass_Besselink_2', 'BBypass_Besselink_3', 'BBypass_Besselink_4', 'BBypass_Besselink_5', # visdrempels vispassage De Berkel\n",
    "        'kst_ST80950035', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Leesten)\n",
    "        'kst_ST84930001', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Noorderhaven)\n",
    "    ], \n",
    "    node_ids_to_include=[\n",
    "        # 1455, # extra punt rondom verdeelpunt De Berkel\n",
    "    ],\n",
    "    node_ids_to_exclude=[],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basins (gdf) based on nodes, edges, split_node_ids and areas\n",
    "network.create_basins_based_on_split_nodes();\n",
    "# Export to geopackage\n",
    "network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find and create ribasim_edges_gdf between basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = (network.split_nodes[['mesh1d_nNodes','geometry', 'split_type']]\n",
    "        .rename(columns={\"geometry\":\"geom_split_node\"}))\n",
    "# check if split_node is used (split_type)\n",
    "conn = conn[conn['split_type']!='no_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge splitnodes add connected edges\n",
    "conn_ds = conn.merge(\n",
    "    network.edges_gdf[['basin', 'start_node_no', 'end_node_no','mesh1d_nEdges']],\n",
    "    left_on='mesh1d_nNodes', \n",
    "    right_on='start_node_no'\n",
    ")\n",
    "conn_us = conn.merge(\n",
    "    network.edges_gdf[['basin', 'start_node_no','end_node_no','mesh1d_nEdges']],\n",
    "    left_on='mesh1d_nNodes', \n",
    "    right_on='end_node_no'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge splitnodes with basin DOWNSTREAM\n",
    "conn_ds = conn_ds.merge(\n",
    "    network.basins_gdf[['basin', 'geometry']], \n",
    "    left_on='basin', \n",
    "    right_on='basin'\n",
    ").rename(columns={\"geometry\":\"geom_basin\"})\n",
    "conn_ds['side'] = 'downstream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge splitnodes with basin UPSTREAM\n",
    "conn_us = conn_us.merge(\n",
    "    network.basins_gdf[['basin', 'geometry']], \n",
    "    left_on='basin', \n",
    "    right_on='basin'\n",
    ").rename(columns={\"geometry\": \"geom_basin\"})\n",
    "conn_us['side'] = 'upstream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE UPSTREAM AND DOWNSTREAM\n",
    "conn = pd.concat([conn_ds, conn_us])\n",
    "conn = conn.drop(columns=['geom_split_node','geom_basin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge basin connections with nodes\n",
    "conn_us = conn_us.merge(\n",
    "    network.nodes_gdf[['mesh1d_nNodes', 'geometry']], \n",
    "    left_on='start_node_no', \n",
    "    right_on='mesh1d_nNodes', \n",
    "    suffixes=('', '_x')\n",
    ").rename(columns={\"geometry\":\"edge_start_node\"}).drop('mesh1d_nNodes_x', axis=1)\n",
    "conn_us[\"edge_start_node_x\"] = conn_us.edge_start_node.apply(lambda p: p.x)\n",
    "conn_us[\"edge_start_node_y\"] = conn_us.edge_start_node.apply(lambda p: p.y)\n",
    "conn_ds = conn_ds.merge(\n",
    "    network.nodes_gdf[['mesh1d_nNodes', 'geometry']], \n",
    "    left_on='end_node_no', \n",
    "    right_on='mesh1d_nNodes', \n",
    "    suffixes=('', '_x')\n",
    ").rename(columns={\"geometry\":\"edge_end_node\"}).drop('mesh1d_nNodes_x', axis=1)\n",
    "conn_ds[\"edge_end_node_x\"] = conn_ds.edge_end_node.apply(lambda p: p.x)\n",
    "conn_ds[\"edge_end_node_y\"] = conn_ds.edge_end_node.apply(lambda p: p.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge upstream and downstream connections\n",
    "conn = conn_us.merge(\n",
    "    conn_ds.drop(columns=['geom_split_node', 'split_type']), \n",
    "    left_on='mesh1d_nNodes',\n",
    "    right_on='mesh1d_nNodes',\n",
    "    suffixes=('_us', '_ds')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coordinate in middle of two nodes upstream and downstream of splitpoint\n",
    "conn['extra_point_x'] = (conn.edge_start_node_x + conn.edge_end_node_x)/2\n",
    "conn['extra_point_y'] = (conn.edge_start_node_y + conn.edge_end_node_y)/2\n",
    "conn['extra_point'] = gpd.points_from_xy(conn['extra_point_x'], conn['extra_point_y'])\n",
    "\n",
    "conn['edge_us'] = conn.apply(lambda row: LineString([row['geom_basin_us'], row['extra_point']]), axis=1)\n",
    "conn['edge_ds'] = conn.apply(lambda row: LineString([row['extra_point'], row['geom_basin_ds']]), axis=1)\n",
    "conn['geometry'] = conn.apply(lambda row: LineString([row['geom_basin_us'], row['extra_point'], row['geom_basin_ds']]), axis=1)\n",
    "conn = gpd.GeoDataFrame(conn, geometry='geometry', crs=28992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_us = gpd.GeoDataFrame(\n",
    "    data=(conn[['mesh1d_nNodes', 'split_type', 'edge_us', 'basin_us', 'mesh1d_nEdges_us', 'side_us']]\n",
    "          .rename(columns={'edge_us': 'geometry', 'basin_us': 'basin', 'side_us': 'side', 'mesh1d_nEdges_us': 'mesh1d_nEdges'})), \n",
    "    geometry='geometry', \n",
    "    crs=28992\n",
    ")\n",
    "conn_ds = gpd.GeoDataFrame(\n",
    "    data=(conn[['mesh1d_nNodes', 'split_type', 'edge_ds', 'basin_ds', 'mesh1d_nEdges_ds', 'side_ds']]\n",
    "          .rename(columns={'edge_ds': 'geometry', 'basin_ds': 'basin', 'side_ds': 'side', 'mesh1d_nEdges_ds': 'mesh1d_nEdges'})), \n",
    "    geometry='geometry', \n",
    "    crs=28992\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ribasim_edges = pd.concat([conn_us, conn_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.ribasim_edges_gdf = ribasim_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export everything to geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.export_to_geopackage(output_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.edges_gdf.basin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:12:32) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfc666eb4a62d5826d85bcfe032d59ef4dfc699941e19e14832498fb495ee494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
