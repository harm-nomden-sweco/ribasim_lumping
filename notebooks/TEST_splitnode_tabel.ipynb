{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ribasim_lumping import create_ribasim_lumping_network\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base_dir, results_dir and network name\n",
    "base_dir = Path(\"..\\\\..\\\\ribasim_lumping_data\\\\\")\n",
    "dhydro_dir = Path(base_dir, \"d-hydro\")\n",
    "results_dir = Path(base_dir, \"results\")\n",
    "network_name = \"tki_zutphen_berkel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load areas (discharge units: afwaterende eenheden)\n",
    "areas_file_path = Path(base_dir, \"afw_eenheden\", f\"{network_name}_afw_eenheden.shp\")\n",
    "areas_gdf = gpd.read_file(areas_file_path)\n",
    "areas_gdf = areas_gdf[['GFEIDENT', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networkanalysis\n",
    "network = create_ribasim_lumping_network(\n",
    "    name=network_name, \n",
    "    dhydro_dir=dhydro_dir,\n",
    "    results_dir=results_dir,\n",
    "    areas_gdf=areas_gdf,\n",
    ")\n",
    "# network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add simulation sets for winter, summer, etc.\n",
    "network.add_data_from_simulations_set(\n",
    "    set_name=\"winter\",\n",
    "    simulations_dir=dhydro_dir,\n",
    "    simulations_names=[\"tki_zuthpen_berkel_basis.dsproj_data\"],\n",
    "    simulation_output_dir=\"FlowFM\\\\output\",\n",
    "    simulations_ts=pd.date_range(\"2000-01-02 23:00\", periods=9, freq=\"6D\"),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read network data and extract all objects (weirs/pumps/laterals/confluences/bifurcations)\n",
    "network.get_network_data()\n",
    "# network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define locations where the network should be split into Ribasim basins:\n",
    "network.add_split_nodes(\n",
    "    weirs=True,\n",
    "    pumps=True,\n",
    "    uniweirs=True,\n",
    "    edges=False,\n",
    "    structures_ids_to_include=[\n",
    "        'kdu_DR80760025', # duiker vispassage bovenstrooms\n",
    "        'kst_ST80830001', 'kst_ST80810015', # onderdoorlaten bij verdeelpunt De Berkel (Zutphen)\n",
    "        'kdu_DR84930010', # duiker met terugslagklep Zutphen Noorderhaven (parallel aan gemaal)\n",
    "        'kdu_DR80950033', # duikers voor wijk Leesten\n",
    "        'kdu_DR80940046', 'kdu_DR80950043', 'kdu_DR80950151', # duikers voor wijk Zuidwijken\n",
    "        'kdu_DR80950103',\n",
    "        'kdu_DR80740070', # inlaat twentekanaal\n",
    "    ], \n",
    "    structures_ids_to_exclude=[\n",
    "        'BCAL_3', 'BCAL_11', # stuwen voor hoogwaterafvoer De Berkel\n",
    "        'BBypass_Besselink_1', 'BBypass_Besselink_2', 'BBypass_Besselink_3', 'BBypass_Besselink_4', 'BBypass_Besselink_5', # visdrempels vispassage De Berkel\n",
    "        'kst_ST80950035', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Leesten)\n",
    "        'kst_ST84930001', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Noorderhaven)\n",
    "        'kst_ST80830045', # weir tussen uitstroompunten Zutphen\n",
    "    ], \n",
    "    edge_ids_to_include=[],\n",
    "    node_ids_to_include=[\n",
    "        419, # voorbeeld splitsing\n",
    "        1784, 2542 # splitsing afleidingskanaal\n",
    "        # 1455, # extra punt rondom verdeelpunt De Berkel\n",
    "    ],\n",
    "    node_ids_to_exclude=[],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basins (gdf) based on nodes, edges, split_node_ids and areas\n",
    "network.create_basins_and_connections_based_on_split_nodes();\n",
    "# Export to geopackage\n",
    "network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify translation split_nodes to ribasim-nodes per type\n",
    "split_node_type_conversion = {\n",
    "    'weir': 'TabulatedRatingCurve', \n",
    "    'uniweir': 'TabulatedRatingCurve' ,\n",
    "    'pump': 'Pump', \n",
    "    'culvert': 'TabulatedRatingCurve', \n",
    "    'manual': 'ManningResistance',\n",
    "    'orifice' : 'TabulatedRatingCurve',\n",
    "    'edge': 'ManningResistance',\n",
    "}\n",
    "# specify translation for specific split_nodes to ribasim-nodes\n",
    "split_node_id_conversion = {\n",
    "    'sto_AE80770024': 'ManningResistance', \n",
    "    'kdu_DR80740070': 'ManningResistance',\n",
    "    # duikers voor wijk Zuidwijken\n",
    "    'kdu_DR80940046': 'ManningResistance', \n",
    "    'kdu_DR80950043': 'ManningResistance', \n",
    "    'kdu_DR80950151': 'ManningResistance', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Ribasim model en exporteer naar geopackage\n",
    "ribasim_model = network.generate_ribasim_model(\n",
    "    split_node_type_conversion=split_node_type_conversion, \n",
    "    split_node_id_conversion=split_node_id_conversion\n",
    ")\n",
    "ribasim_model.write(f\"{results_dir}/{network.name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for writing and reading excel with structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_structures_to_excel(network):\n",
    "    \"\"\" export all structures and splitnode info to excel file with seperate sheet per structure type\n",
    "     input: network with structure gdfs, splitnodes, split node type conversion tables \"\"\"\n",
    "\n",
    "    from typing import Dict\n",
    "    list_gdfs = [\n",
    "        # network.stations_gdf,\n",
    "        network.pumps_gdf,\n",
    "        network.weirs_gdf,\n",
    "        network.orifices_gdf,\n",
    "        network.bridges_gdf,\n",
    "        network.culverts_gdf,\n",
    "        network.uniweirs_gdf\n",
    "    ]\n",
    "    structures = pd.DataFrame(\n",
    "        columns=['mesh1d_node_id', 'mesh1d_nEdges', 'geometry', 'object_type'],\n",
    "    )\n",
    "\n",
    "    if network.split_nodes is not None:\n",
    "        splitnodes = network.split_nodes.copy()\n",
    "        # splitnodes['splitnode']='yes'\n",
    "\n",
    "    with pd.ExcelWriter(f\"{results_dir}/{network.name}/structures.xlsx\") as writer:  \n",
    "        for gdf in list_gdfs:\n",
    "            if gdf is not None:\n",
    "                # merge structure gdf with splitnode\n",
    "                if network.split_nodes is not None:\n",
    "                    if network.split_node_type_conversion is not None:\n",
    "                        # voeg conversie tabel toe\n",
    "                        split_node_type_conversion = network.split_node_type_conversion\n",
    "                        if isinstance(split_node_type_conversion, Dict):\n",
    "                            for key, value in split_node_type_conversion.items():\n",
    "                                splitnodes['type'] = splitnodes['split_type'].replace(split_node_type_conversion)\n",
    "                        \n",
    "                        split_node_id_conversion = network.split_node_id_conversion\n",
    "                        if isinstance(split_node_id_conversion, Dict):\n",
    "                            for key, value in split_node_id_conversion.items():\n",
    "                                if len(splitnodes[splitnodes['mesh1d_node_id'] == key]) == 0:\n",
    "                                    print(f\" * split_node type conversion id={key} (type={value}) does not exist\")\n",
    "                                splitnodes.loc[splitnodes['mesh1d_node_id'] == key, 'type'] = value\n",
    "                    # merge structures with splitnodes\n",
    "                    structure = gdf.merge(splitnodes, left_on='mesh1d_node_id', right_on='mesh1d_node_id', how='left', suffixes=('', '_spl'),indicator=True)\n",
    "                    structure['use_splitnode'] = structure['_merge'].map({'both': 'yes', 'left_only': 'no'})\n",
    "                else:\n",
    "                    structure=gdf.copy()\n",
    "                    \n",
    "                # save structures in excelfile, with seperate sheet per structuretype \n",
    "                if not structure.empty:\n",
    "                    struct_name=structure['object_type'][0]\n",
    "                    print(f'write {struct_name} to excel')\n",
    "                    structure = structure[structure.columns & ['mesh1d_node_id', 'projection_x', 'projection_y', 'object_type','use_splitnode','status','splitnode','type']]\n",
    "                    structure.to_excel(writer, sheet_name=struct_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_structures_from_excel(excel_path):\n",
    "    \"\"\" import all structure ids from excelfile \n",
    "    and output:\n",
    "    - dictionary with excel data\n",
    "    - list of structures to include as splitnode \n",
    "    - dictionary with structure ids and splitnode conversion type \"\"\"\n",
    "    \n",
    "    structures_excel = pd.read_excel(excel_path, sheet_name=None) #sheet_name None to read all sheets as dictionary\n",
    "\n",
    "    structures_ids_to_include_as_splitnode = []\n",
    "    split_node_id_conversion = dict()\n",
    "\n",
    "    for key in structures_excel:\n",
    "        structure_name = key\n",
    "        structure_df = structures_excel.get(structure_name)\n",
    "        print(f'read sheet {key}')\n",
    "        # structure_df = structures_excel.get('pump')\n",
    "        \n",
    "        # filter the structures to use as splitnode and add to list structures_ids_to_include_as_splitnode\n",
    "        if 'use_splitnode' not in structure_df.columns:\n",
    "            print(f'- no column named use_splitnode found in sheet {key}')\n",
    "            \n",
    "        else:\n",
    "            structure_splitnodes = structure_df.loc[structure_df['use_splitnode'] == 'yes' ] \n",
    "            structure_ids = list(structure_splitnodes['mesh1d_node_id'])\n",
    "            structures_ids_to_include_as_splitnode = structures_ids_to_include_as_splitnode + structure_ids\n",
    "\n",
    "            if 'type' not in structure_df.columns:\n",
    "                print(f'- no column named type found in sheet {key}')\n",
    "            else:\n",
    "                # convert to dictionary for split_node_id_conversion\n",
    "                structure_dict = dict(zip(structure_splitnodes['mesh1d_node_id'], structure_splitnodes['type']))\n",
    "                split_node_id_conversion.update(structure_dict)\n",
    "\n",
    "            \n",
    "    return structures_excel, structures_ids_to_include_as_splitnode, split_node_id_conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_structures_to_excel(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = f\"{results_dir}/{network.name}/structures_input.xlsx\"\n",
    "structures_ids_to_include_as_splitnode, split_node_id_conversion  = read_structures_from_excel(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfc666eb4a62d5826d85bcfe032d59ef4dfc699941e19e14832498fb495ee494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
