{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ribasim_lumping import RibasimLumpingNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "import ribasim\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaDeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base_dir, results_dir and network name\n",
    "base_dir = Path(\"..\\\\..\\\\ribasim_lumping_data\\\\\")\n",
    "results_dir = Path(base_dir, \"results\")\n",
    "network_name = \"zutphen_tki_netwerk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"fiona\\ogrext.pyx\", line 136, in fiona.ogrext.gdal_open_vector\n",
      "  File \"fiona\\_err.pyx\", line 291, in fiona._err.exc_wrap_pointer\n",
      "fiona._err.CPLE_OpenFailedError: ..\\..\\ribasim_lumping_data\\afw_eenheden\\wrij_afwateringseenheden_selectie_Zutphen.shp: No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\NLTAND\\AppData\\Local\\Temp\\ipykernel_8232\\1770911492.py\", line 3, in <module>\n",
      "    areas_gdf = gpd.read_file(areas_file_path)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\geopandas\\io\\file.py\", line 259, in _read_file\n",
      "    return _read_file_fiona(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\geopandas\\io\\file.py\", line 303, in _read_file_fiona\n",
      "    with reader(path_or_bytes, **kwargs) as features:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\fiona\\env.py\", line 457, in wrapper\n",
      "    return f(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\fiona\\__init__.py\", line 336, in open\n",
      "    colxn = Collection(\n",
      "            ^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\fiona\\collection.py\", line 234, in __init__\n",
      "    self.session.start(self, **kwargs)\n",
      "  File \"fiona\\ogrext.pyx\", line 587, in fiona.ogrext.Session.start\n",
      "  File \"fiona\\ogrext.pyx\", line 143, in fiona.ogrext.gdal_open_vector\n",
      "fiona.errors.DriverError: ..\\..\\ribasim_lumping_data\\afw_eenheden\\wrij_afwateringseenheden_selectie_Zutphen.shp: No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\inspect.py\", line 1252, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\ribasim\\Lib\\inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "# Load areas (discharge units: afwaterende eenheden)\n",
    "areas_file_path = Path(base_dir, \"afw_eenheden\\\\wrij_afwateringseenheden_selectie_Zutphen.shp\")\n",
    "areas_gdf = gpd.read_file(areas_file_path)\n",
    "areas_gdf = areas_gdf[['GFEIDENT', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networkanalysis\n",
    "network = RibasimLumpingNetwork(\n",
    "    name=network_name, \n",
    "    results_dir=results_dir,\n",
    "    areas_gdf=areas_gdf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Simulation set (winter): tki_zuthpen_berkel_basis.dsproj_data | Timestamps: 9 | his.nc and map.nc\n"
     ]
    }
   ],
   "source": [
    "# Select simulation sets and extract all data using xugrid/ugrid\n",
    "network.add_data_from_simulations_set(\n",
    "    set_name=\"winter\",\n",
    "    simulations_dir=Path(base_dir, \"d-hydro\\\\\"),\n",
    "    simulations_names=[\"tki_zuthpen_berkel_basis.dsproj_data\"],\n",
    "    simulation_output_dir=\"FlowFM\\\\output\",\n",
    "    simulations_ts=pd.date_range(\"2000-01-02 23:00\", periods=9, freq=\"2D\"),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_name = 'tki_zuthpen_berkel_basis.dsproj_data'\n",
    "file_bc = f'{base_dir}\\\\d-hydro\\\\{simulation_name}\\\\FlowFM\\\\input\\\\FlowFM_boundaryconditions1d.bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D-HYDRO-network analysed:\n",
      " - nodes and waterlevels\n",
      " - edges and discharges\n",
      " - stations / pumps / weirs / orifices / bridges / culverts / uniweirs / confluences / bifurcations / boundaries\n"
     ]
    }
   ],
   "source": [
    "# Read network data and extract all objects (weirs/pumps/laterals/confluences/bifurcations)\n",
    "network.get_network_data(file_bc)\n",
    "# Export to geopackage\n",
    "# network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 split locations\n",
      " - pump: 4\n",
      " - weir: 46\n",
      " - uniweir: 9\n",
      " - orifice: 2\n",
      " - culvert: 6\n"
     ]
    }
   ],
   "source": [
    "# Define locations where the network should be split into Ribasim basins:\n",
    "\n",
    "network.add_split_nodes(\n",
    "    weirs=True,\n",
    "    pumps=True,\n",
    "    uniweirs=True,\n",
    "    structures_ids_to_include=[\n",
    "        'kdu_DR80760025', # duiker vispassage bovenstrooms\n",
    "        'kst_ST80830001', 'kst_ST80810015', # onderdoorlaten bij verdeelpunt De Berkel (Zutphen)\n",
    "        'kdu_DR84930010', # duiker met terugslagklep Zutphen Noorderhaven (parallel aan gemaal)\n",
    "        'kdu_DR80950033', # duikers voor wijk Leesten\n",
    "        'kdu_DR80940046', 'kdu_DR80950043', 'kdu_DR80950151' # duikers voor wijk Zuidwijken\n",
    "    ], \n",
    "    structures_ids_to_exclude=[\n",
    "        'BCAL_3', 'BCAL_11', # stuwen voor hoogwaterafvoer De Berkel\n",
    "        'BBypass_Besselink_1', 'BBypass_Besselink_2', 'BBypass_Besselink_3', 'BBypass_Besselink_4', 'BBypass_Besselink_5', # visdrempels vispassage De Berkel\n",
    "        'kst_ST80950035', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Leesten)\n",
    "        'kst_ST84930001', # verwarrende stuw ivm afwaterende eenheid (Zutphen: Noorderhaven)\n",
    "    ], \n",
    "    node_ids_to_include=[\n",
    "        # 419, # voorbeeld splitsing\n",
    "        # 1455, # extra punt rondom verdeelpunt De Berkel\n",
    "    ],\n",
    "    node_ids_to_exclude=[],\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create basins using split nodes:\n",
      " - create network graph from nodes/edges\n",
      " - split network graph at split locations\n",
      " - define numbers Ribasim-Basins and join edges/nodes\n",
      " - check whether each split location results in a split\n",
      " - create final locations Ribasim-Basins\n",
      " - define for each Ribasim-Basin the related basin area\n",
      " - create Ribasim-Edges between Boundary and Basin\n",
      " - create Ribasim-Edges between Basins and split locations\n",
      "Exporting to geopackage:\n",
      " - areas, nodes, edges, stations, pumps, weirs, orifices, bridges, culverts, uniweirs, basin_areas, split_nodes, basins, basin_connections, boundaries, boundary_basin_connections, \n",
      " - not available: \n",
      "Export location: ..\\..\\ribasim_lumping_data\\results\\zutphen_tki_netwerk\\ribasim_network.qgz\n"
     ]
    }
   ],
   "source": [
    "# Create basins (gdf) based on nodes, edges, split_node_ids and areas\n",
    "network.create_basins_and_connections_based_on_split_nodes();\n",
    "# Export to geopackage\n",
    "network.export_to_geopackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to ribasim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set id's to node. Start with basins, then boundaries and then splitnodes. start with id 1\n",
    "basins_gdf =network.basins_gdf.copy()\n",
    "basins_gdf['node_id'] = basins_gdf['basin'] + 1\n",
    "basins_gdf['type'] = 'Basin'\n",
    "\n",
    "boundaries_gdf = network.boundaries_gdf.copy()\n",
    "boundaries_gdf['node_id'] = boundaries_gdf['boundary_id'] + len(network.basins_gdf) +1\n",
    "boundaries_gdf['type'] = 'LevelBoundary'\n",
    "\n",
    "splitnodes_gdf = network.split_nodes.copy()\n",
    "splitnodes_gdf.insert(0, 'splitnode_id', range(len(splitnodes_gdf)))\n",
    "splitnodes_gdf['node_id'] = splitnodes_gdf['splitnode_id'] + len(network.basins_gdf) + len(network.boundaries_gdf) +1\n",
    "splitnodes_gdf['type'] = 'TabulatedRatingCurve' \n",
    "splitnodetypes = {\n",
    "    'weir': 'TabulatedRatingCurve', \n",
    "    'uniweir': 'TabulatedRatingCurve' ,\n",
    "    'pump': 'Pump', \n",
    "    'weir': 'TabulatedRatingCurve', \n",
    "    'culvert':'ManningResistance', \n",
    "    'manual': 'ManningResistance',\n",
    "    'orifice' : 'TabulatedRatingCurve'\n",
    "}\n",
    "for nodetype in splitnodetypes:\n",
    "    splitnodes_gdf.loc[splitnodes_gdf['split_type']==nodetype, 'type'] = splitnodetypes[nodetype]\n",
    "\n",
    "# concat nodes\n",
    "ribasim_node_gdf = pd.concat([basins_gdf, boundaries_gdf,splitnodes_gdf]).set_crs(basins_gdf.crs)\n",
    "ribasim_node_gdf = ribasim_node_gdf.set_index('node_id')\n",
    "ribasim_node_gdf = ribasim_node_gdf[['geometry', 'type']]\n",
    "node = ribasim.Node(static=ribasim_node_gdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_connections_gdf = network.basin_connections_gdf[['mesh1d_node_id', 'basin_in','basin_out','geometry']]\n",
    "\n",
    "# merge to find splitnode id\n",
    "basin_connections_gdf = basin_connections_gdf.merge(splitnodes_gdf[['splitnode_id','mesh1d_node_id', 'node_id']], left_on='mesh1d_node_id', right_on='mesh1d_node_id')\n",
    "\n",
    "# split connections in the connections upstream and downstream of splitnode\n",
    "# add node ID's \n",
    "basin_connections_gdf_us = basin_connections_gdf.copy()\n",
    "basin_connections_gdf_us['geometry'] = basin_connections_gdf_us.geometry.apply(lambda x: LineString([x.coords[0], x.coords[1]]))\n",
    "basin_connections_gdf_us['from_node_id'] = basin_connections_gdf_us['basin_out'] +1\n",
    "basin_connections_gdf_us['to_node_id'] = basin_connections_gdf_us['node_id']\n",
    "\n",
    "basin_connections_gdf_ds = basin_connections_gdf.copy()\n",
    "basin_connections_gdf_ds['geometry'] = basin_connections_gdf.geometry.apply(lambda x: LineString([x.coords[1], x.coords[2]]))\n",
    "basin_connections_gdf_ds['from_node_id'] = basin_connections_gdf_ds['node_id']\n",
    "basin_connections_gdf_ds['to_node_id'] = basin_connections_gdf_ds['basin_in'] +1\n",
    "\n",
    "\n",
    "# boundary basin connections - add node ID's\n",
    "boundary_basin_connections = network.boundary_basin_connections_gdf[['boundary_id', 'basin','geometry','boundary_location']].copy()\n",
    "\n",
    "boundary_basin_connections_us = boundary_basin_connections.loc[boundary_basin_connections['boundary_location'] == 'upstream'].copy()\n",
    "boundary_basin_connections_us['from_node_id'] = boundary_basin_connections_us['boundary_id']  + len(network.basins_gdf) +1\n",
    "boundary_basin_connections_us['to_node_id'] = boundary_basin_connections_us['basin'] +1\n",
    "\n",
    "boundary_basin_connections_ds = boundary_basin_connections.loc[boundary_basin_connections['boundary_location'] == 'downstream'].copy()\n",
    "boundary_basin_connections_ds['from_node_id'] = boundary_basin_connections_ds['basin'] +1\n",
    "boundary_basin_connections_ds['to_node_id'] = boundary_basin_connections_ds['boundary_id'] + len(network.basins_gdf) +1\n",
    "\n",
    "# Setup the edges:\n",
    "ribasim_edges = pd.concat([basin_connections_gdf_ds, basin_connections_gdf_us,boundary_basin_connections_us, boundary_basin_connections_ds]) \n",
    "ribasim_edges = ribasim_edges[['from_node_id','to_node_id','geometry']].reset_index()\n",
    "ribasim_edges['from_node_id'].astype(int)\n",
    "\n",
    "edge = ribasim.Edge(static=ribasim_edges)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyvalue = 5.5\n",
    "\n",
    "# basin\n",
    "profile_data = pd.DataFrame(\n",
    "    data={\n",
    "        \"node_id\": ribasim_node_gdf.loc[ribasim_node_gdf['type']=='Basin'].index.values.tolist()\n",
    "    }\n",
    ")\n",
    "profile_data['storage'] = dummyvalue\n",
    "profile_data['area'] = dummyvalue\n",
    "profile_data['level'] = dummyvalue\n",
    "\n",
    "static_data = pd.DataFrame(\n",
    "    data={\n",
    "        \"node_id\": ribasim_node_gdf.loc[ribasim_node_gdf['type']=='Basin'].index.values.tolist()\n",
    "    }\n",
    ")\n",
    "static_data['drainage'] = dummyvalue\n",
    "static_data['potential_evaporation'] = dummyvalue\n",
    "static_data['infiltration'] = dummyvalue\n",
    "static_data['precipitation'] = dummyvalue\n",
    "static_data['urban_runoff'] = dummyvalue\n",
    "\n",
    "basin = ribasim.Basin(profile=profile_data, static=static_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulated_rating_curve\n",
    "static_data = pd.DataFrame(\n",
    "    data={\n",
    "        \"node_id\": ribasim_node_gdf.loc[ribasim_node_gdf['type']=='TabulatedRatingCurve'].index\n",
    "    }\n",
    ")\n",
    "static_data['level'] = dummyvalue\n",
    "static_data['discharge'] = dummyvalue\n",
    "\n",
    "tabulated_rating_curve = ribasim.TabulatedRatingCurve(static=static_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manning_resistance\n",
    "static_data = pd.DataFrame(\n",
    "    data={\n",
    "        \"node_id\": ribasim_node_gdf.loc[ribasim_node_gdf['type']=='ManningResistance'].index\n",
    "    }\n",
    ")\n",
    "static_data['length'] = dummyvalue\n",
    "static_data['manning_n'] = dummyvalue\n",
    "static_data['profile_width'] = dummyvalue\n",
    "static_data['profile_slope'] = dummyvalue\n",
    "\n",
    "manning_resistance = ribasim.ManningResistance(static= static_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level_boundary\n",
    "static_boundary = boundaries_gdf[['node_id']].copy()\n",
    "static_boundary['level'] = dummyvalue\n",
    "\n",
    "level_boundary = ribasim.LevelBoundary(static=static_boundary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pump\n",
    "static_pump = pd.DataFrame(\n",
    "    data={\n",
    "        \"node_id\": ribasim_node_gdf.loc[ribasim_node_gdf['type']=='Pump'].index.values.tolist()\n",
    "    }\n",
    ")\n",
    "static_pump['flow_rate'] = 0.0\n",
    "\n",
    "pump = ribasim.Pump(static=static_pump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export everything to geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = ribasim.Model(\n",
    "    modelname=\"ribasim_model\",\n",
    "    node=node,\n",
    "    edge=edge,\n",
    "    basin=basin,\n",
    "    level_boundary=level_boundary,\n",
    "    pump=pump,\n",
    "    tabulated_rating_curve=tabulated_rating_curve,\n",
    "    manning_resistance=manning_resistance, \n",
    "    starttime=\"2020-01-01 00:00:00\",\n",
    "    endtime=\"2021-01-01 00:00:00\",\n",
    ")\n",
    "\n",
    "# Write the model to a TOML and GeoPackage:\n",
    "# model.write(f\"{results_dir}/{network.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ribasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfc666eb4a62d5826d85bcfe032d59ef4dfc699941e19e14832498fb495ee494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
